{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07726167-0900-4775-b08f-e295e13898a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from timm import data, loss\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc3989e-d180-4534-b964-735c12d87763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize(224),\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n",
    "    transforms.RandomGrayscale(0.2),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(0.5, 0.2),\n",
    "    transforms.GaussianBlur(3, (0.1, 0.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071,0.4867,0.4408),(0.2675,0.2565,0.2761)),\n",
    "    transforms.RandomErasing(0.3, (0.05, 0.2))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75971f7-8c03-48a0-bcf0-7747d15baee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071,0.4867,0.4408),(0.2675,0.2565,0.2761))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06c2f00-b5af-41e2-a2c2-d345d0d70265",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = data.Mixup(\n",
    "    mixup_alpha=0.8,\n",
    "    cutmix_alpha=0.8,\n",
    "    prob=1.0,\n",
    "    switch_prob=0.5,\n",
    "    mode=\"batch\",\n",
    "    label_smoothing=0.1,\n",
    "    num_classes=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d3b9b4-b48b-4620-ad42-9dc47a094495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading CIFAR100 dataset\n",
    "train_dataset = datasets.CIFAR100(root=\"./data\", train=True, download=False, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR100(root=\"./data\", train=False, download=False, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56dd44fe-bf49-455e-bd0d-b1023653bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into training and validation subsets.\n",
    "val_ratio = 0.1\n",
    "train_size = int((1 - val_ratio) * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d61859a-4b64-487e-929e-98e12c5428ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 45000 | Test size: 10000 | Validation size: 5000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {train_size} | Test size: {len(test_dataset)} | Validation size: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d050f051-f24c-4cab-b361-90ef15f3d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders: train (shuffled), val/test (no shuffle)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153b5483-d764-4d5a-9be5-5d60dd231b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device, scheduler=None, mix_fn=None):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        images, labels = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n",
    "\n",
    "        if mix_fn is not None:\n",
    "            images, labels = mix_fn(images, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "                    \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7e065b-c85a-491f-b46b-dd63604b6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = 100 * (correct / total)\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a49352d-82b9-40f0-83bc-d60eb66b5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_layers(model, stage):\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    if stage >= 1:\n",
    "        for p in model.fc.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    if stage >= 2:\n",
    "        for p in model.layer4.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in model.layer3.parameters():\n",
    "            p.requires_grad=True\n",
    "\n",
    "    if stage >= 3:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    tqdm.write(f\"Trainable params: {trainable_params:,} / {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76566113-dd4f-44da-bc2d-b1aad15f3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "num_features = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c60fb8-9058-4e59-b092-0e3db190f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ede85a-416b-4e7d-9ad5-daa09edff258",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_train = loss.SoftTargetCrossEntropy()\n",
    "loss_fn_eval = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, resnet50.parameters()), lr=0.01, weight_decay=5e-4, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f29a042-6506-41e6-8d23-2943a5d3bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "patience_counter = 1\n",
    "max_patience = 10\n",
    "current_stage = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "641035cf-2f96-40c5-a70c-b8de18fa4fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                      | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1: Training only FC layer\n",
      "Trainable params: 204,900 / 23,712,932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                      | 0/100 [09:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [001/100] | Train Loss: 4.4893 | Val Loss: 4.1869 | Acc:  19.72% | Current LR(s): [0.002801]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   1%|▍                                         | 1/100 [09:41<15:58:57, 581.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [001/100] | Val Loss: 4.18686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   1%|▍                                         | 1/100 [18:52<15:58:57, 581.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [002/100] | Train Loss: 4.1252 | Val Loss: 3.6931 | Acc:  28.60% | Current LR(s): [0.007602]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   2%|▊                                         | 2/100 [19:16<15:43:09, 577.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [002/100] | Val Loss: 3.69313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   2%|▊                                         | 2/100 [28:25<15:43:09, 577.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [003/100] | Train Loss: 3.9124 | Val Loss: 3.3788 | Acc:  33.86% | Current LR(s): [0.010000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   3%|█▎                                        | 3/100 [28:55<15:35:17, 578.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [003/100] | Val Loss: 3.37882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   3%|█▎                                        | 3/100 [38:04<15:35:17, 578.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [004/100] | Train Loss: 3.7892 | Val Loss: 3.1834 | Acc:  35.64% | Current LR(s): [0.009504]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   4%|█▋                                        | 4/100 [38:28<15:21:41, 576.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [004/100] | Val Loss: 3.18339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   4%|█▋                                        | 4/100 [48:35<15:21:41, 576.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [005/100] | Train Loss: 3.7332 | Val Loss: 3.0662 | Acc:  36.60% | Current LR(s): [0.008116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   5%|██                                        | 5/100 [48:52<15:39:26, 593.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [005/100] | Val Loss: 3.06622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   5%|██                                      | 5/100 [1:00:43<15:39:26, 593.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [006/100] | Train Loss: 3.7090 | Val Loss: 3.0191 | Acc:  35.54% | Current LR(s): [0.006111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   6%|██▍                                     | 6/100 [1:01:06<16:44:41, 641.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [006/100] | Val Loss: 3.01914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   6%|██▍                                     | 6/100 [1:11:34<16:44:41, 641.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [007/100] | Train Loss: 3.6943 | Val Loss: 2.9689 | Acc:  37.64% | Current LR(s): [0.003886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   7%|██▊                                     | 7/100 [1:11:49<16:34:55, 641.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [007/100] | Val Loss: 2.96891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   7%|██▊                                     | 7/100 [1:22:06<16:34:55, 641.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [008/100] | Train Loss: 3.6624 | Val Loss: 2.9411 | Acc:  39.68% | Current LR(s): [0.001881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   8%|███▏                                    | 8/100 [1:22:24<16:20:43, 639.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [008/100] | Val Loss: 2.94107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   9%|███▌                                    | 9/100 [1:32:31<15:54:38, 629.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [009/100] | Train Loss: 3.6488 | Val Loss: 2.9733 | Acc:  38.78% | Current LR(s): [0.000495]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|███▉                                   | 10/100 [1:42:56<15:42:05, 628.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [010/100] | Train Loss: 3.6269 | Val Loss: 2.9907 | Acc:  38.84% | Current LR(s): [0.000000]\n",
      "No improvement for 2 epochs.\n",
      "Stage 2: Unfreezing layer4 + layer3\n",
      "Trainable params: 22,268,004 / 23,712,932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|███▉                                   | 10/100 [1:54:09<15:42:05, 628.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [011/100] | Train Loss: 3.5093 | Val Loss: 2.3225 | Acc:  46.36% | Current LR(s): [0.000076, 0.000152, 0.000762]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|████▎                                  | 11/100 [1:54:59<16:14:54, 657.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [011/100] | Val Loss: 2.32248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  11%|████▎                                  | 11/100 [2:06:03<16:14:54, 657.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [012/100] | Train Loss: 3.2858 | Val Loss: 1.9450 | Acc:  55.74% | Current LR(s): [0.000218, 0.000437, 0.002184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|████▋                                  | 12/100 [2:06:52<16:28:56, 674.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [012/100] | Val Loss: 1.94502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  12%|████▋                                  | 12/100 [2:18:00<16:28:56, 674.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [013/100] | Train Loss: 3.1333 | Val Loss: 1.7549 | Acc:  59.80% | Current LR(s): [0.000380, 0.000760, 0.003801]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█████                                  | 13/100 [2:18:39<16:31:38, 683.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [013/100] | Val Loss: 1.75493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  13%|█████                                  | 13/100 [2:29:39<16:31:38, 683.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [014/100] | Train Loss: 3.0327 | Val Loss: 1.5926 | Acc:  63.24% | Current LR(s): [0.000486, 0.000971, 0.004856]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█████▍                                 | 14/100 [2:30:17<16:26:38, 688.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [014/100] | Val Loss: 1.59263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  15%|█████▊                                 | 15/100 [2:41:38<16:12:07, 686.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [015/100] | Train Loss: 2.9220 | Val Loss: 1.6032 | Acc:  64.30% | Current LR(s): [0.000497, 0.000994, 0.004972]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  15%|█████▊                                 | 15/100 [2:52:49<16:12:07, 686.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [016/100] | Train Loss: 2.8823 | Val Loss: 1.4377 | Acc:  67.28% | Current LR(s): [0.000475, 0.000950, 0.004752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  16%|██████▏                                | 16/100 [2:53:35<16:13:38, 695.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [016/100] | Val Loss: 1.43770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  16%|██████▏                                | 16/100 [3:04:41<16:13:38, 695.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [017/100] | Train Loss: 2.8185 | Val Loss: 1.4299 | Acc:  68.56% | Current LR(s): [0.000433, 0.000866, 0.004332]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  17%|██████▋                                | 17/100 [3:05:28<16:09:18, 700.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [017/100] | Val Loss: 1.42990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  17%|██████▋                                | 17/100 [3:16:39<16:09:18, 700.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [018/100] | Train Loss: 2.7758 | Val Loss: 1.4131 | Acc:  69.06% | Current LR(s): [0.000375, 0.000750, 0.003750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  18%|███████                                | 18/100 [3:17:31<16:06:44, 707.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [018/100] | Val Loss: 1.41313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  18%|███████                                | 18/100 [3:28:42<16:06:44, 707.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [019/100] | Train Loss: 2.7557 | Val Loss: 1.3542 | Acc:  69.30% | Current LR(s): [0.000306, 0.000611, 0.003056]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  19%|███████▍                               | 19/100 [3:29:32<16:00:15, 711.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [019/100] | Val Loss: 1.35416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|███████▊                               | 20/100 [3:40:44<15:32:55, 699.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [020/100] | Train Loss: 2.7304 | Val Loss: 1.3589 | Acc:  70.46% | Current LR(s): [0.000231, 0.000463, 0.002313]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|███████▊                               | 20/100 [3:52:20<15:32:55, 699.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [021/100] | Train Loss: 2.7140 | Val Loss: 1.3202 | Acc:  71.40% | Current LR(s): [0.000159, 0.000317, 0.001586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  21%|████████▏                              | 21/100 [3:53:09<15:39:05, 713.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [021/100] | Val Loss: 1.32023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  21%|████████▏                              | 21/100 [4:05:02<15:39:05, 713.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [022/100] | Train Loss: 2.7137 | Val Loss: 1.2924 | Acc:  71.88% | Current LR(s): [0.000094, 0.000188, 0.000941]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  22%|████████▌                              | 22/100 [4:05:49<15:45:17, 727.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [022/100] | Val Loss: 1.29242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  22%|████████▌                              | 22/100 [4:17:39<15:45:17, 727.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [023/100] | Train Loss: 2.6700 | Val Loss: 1.2440 | Acc:  72.34% | Current LR(s): [0.000043, 0.000087, 0.000434]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  23%|████████▉                              | 23/100 [4:18:13<15:39:43, 732.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [023/100] | Val Loss: 1.24402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  24%|█████████▎                             | 24/100 [4:29:59<15:17:48, 724.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [024/100] | Train Loss: 2.6432 | Val Loss: 1.3184 | Acc:  71.24% | Current LR(s): [0.000011, 0.000022, 0.000111]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  25%|█████████▊                             | 25/100 [4:41:43<14:57:55, 718.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [025/100] | Train Loss: 2.6433 | Val Loss: 1.3016 | Acc:  71.82% | Current LR(s): [0.000000, 0.000000, 0.000000]\n",
      "No improvement for 2 epochs.\n",
      "Stage 3: Unfreezing all layers\n",
      "Trainable params: 23,712,932 / 23,712,932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  26%|██████████▏                            | 26/100 [4:56:52<15:56:18, 775.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [026/100] | Train Loss: 2.6425 | Val Loss: 1.3472 | Acc:  71.54% | Current LR(s): [0.000002, 0.000004, 0.000013, 0.000036, 0.000089]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  27%|██████████▌                            | 27/100 [5:11:58<16:31:18, 814.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [027/100] | Train Loss: 2.6300 | Val Loss: 1.2757 | Acc:  73.36% | Current LR(s): [0.000003, 0.000006, 0.000018, 0.000047, 0.000117]\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  27%|██████████▌                            | 27/100 [5:27:05<16:31:18, 814.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [028/100] | Train Loss: 2.6551 | Val Loss: 1.2145 | Acc:  72.78% | Current LR(s): [0.000004, 0.000008, 0.000024, 0.000065, 0.000163]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  28%|██████████▉                            | 28/100 [5:27:48<17:06:23, 855.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [028/100] | Val Loss: 1.21453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  29%|███████████▎                           | 29/100 [5:42:59<17:11:37, 871.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [029/100] | Train Loss: 2.6222 | Val Loss: 1.2398 | Acc:  72.62% | Current LR(s): [0.000006, 0.000011, 0.000034, 0.000090, 0.000226]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|███████████▋                           | 30/100 [5:58:24<17:15:45, 887.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [030/100] | Train Loss: 2.6219 | Val Loss: 1.2154 | Acc:  72.70% | Current LR(s): [0.000008, 0.000015, 0.000046, 0.000122, 0.000305]\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  31%|████████████                           | 31/100 [6:13:48<17:13:32, 898.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [031/100] | Train Loss: 2.6076 | Val Loss: 1.2383 | Acc:  73.30% | Current LR(s): [0.000010, 0.000020, 0.000060, 0.000159, 0.000398]\n",
      "No improvement for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  32%|████████████▍                          | 32/100 [6:29:03<17:04:07, 903.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [032/100] | Train Loss: 2.6149 | Val Loss: 1.2146 | Acc:  74.10% | Current LR(s): [0.000013, 0.000025, 0.000075, 0.000201, 0.000503]\n",
      "No improvement for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  33%|████████████▊                          | 33/100 [6:44:11<16:50:21, 904.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [033/100] | Train Loss: 2.5874 | Val Loss: 1.2542 | Acc:  74.30% | Current LR(s): [0.000015, 0.000031, 0.000093, 0.000248, 0.000619]\n",
      "No improvement for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  33%|████████████▊                          | 33/100 [6:59:25<16:50:21, 904.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [034/100] | Train Loss: 2.5675 | Val Loss: 1.1820 | Acc:  74.42% | Current LR(s): [0.000019, 0.000037, 0.000112, 0.000297, 0.000743]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  34%|█████████████▎                         | 34/100 [7:00:07<16:52:22, 920.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [034/100] | Val Loss: 1.18196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  35%|█████████████▋                         | 35/100 [7:15:22<16:35:09, 918.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [035/100] | Train Loss: 2.5549 | Val Loss: 1.1942 | Acc:  74.00% | Current LR(s): [0.000022, 0.000044, 0.000131, 0.000349, 0.000873]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  36%|██████████████                         | 36/100 [7:30:32<16:17:11, 916.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [036/100] | Train Loss: 2.5407 | Val Loss: 1.1883 | Acc:  74.34% | Current LR(s): [0.000025, 0.000050, 0.000151, 0.000403, 0.001007]\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  36%|██████████████                         | 36/100 [7:45:41<16:17:11, 916.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [037/100] | Train Loss: 2.5293 | Val Loss: 1.1146 | Acc:  74.76% | Current LR(s): [0.000029, 0.000057, 0.000171, 0.000456, 0.001140]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  37%|██████████████▍                        | 37/100 [7:46:27<16:14:15, 927.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [037/100] | Val Loss: 1.11461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  37%|██████████████▍                        | 37/100 [8:01:52<16:14:15, 927.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [038/100] | Train Loss: 2.5296 | Val Loss: 1.1125 | Acc:  75.58% | Current LR(s): [0.000032, 0.000064, 0.000191, 0.000509, 0.001272]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  38%|██████████████▊                        | 38/100 [8:02:37<16:11:37, 940.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [038/100] | Val Loss: 1.11249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  39%|███████████████▏                       | 39/100 [8:17:54<15:48:54, 933.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [039/100] | Train Loss: 2.5095 | Val Loss: 1.1250 | Acc:  75.44% | Current LR(s): [0.000035, 0.000070, 0.000210, 0.000560, 0.001400]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|███████████████▌                       | 40/100 [8:33:15<15:29:36, 929.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [040/100] | Train Loss: 2.5283 | Val Loss: 1.1797 | Acc:  75.16% | Current LR(s): [0.000038, 0.000076, 0.000228, 0.000608, 0.001520]\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  41%|███████████████▉                       | 41/100 [8:48:34<15:11:01, 926.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [041/100] | Train Loss: 2.4885 | Val Loss: 1.1338 | Acc:  76.36% | Current LR(s): [0.000041, 0.000082, 0.000245, 0.000652, 0.001631]\n",
      "No improvement for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  42%|████████████████▍                      | 42/100 [9:03:40<14:49:35, 920.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [042/100] | Train Loss: 2.4731 | Val Loss: 1.1129 | Acc:  76.60% | Current LR(s): [0.000043, 0.000087, 0.000260, 0.000692, 0.001731]\n",
      "No improvement for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  43%|████████████████▊                      | 43/100 [9:18:42<14:29:13, 914.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [043/100] | Train Loss: 2.4764 | Val Loss: 1.1363 | Acc:  76.04% | Current LR(s): [0.000045, 0.000091, 0.000273, 0.000727, 0.001817]\n",
      "No improvement for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  43%|████████████████▊                      | 43/100 [9:33:50<14:29:13, 914.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [044/100] | Train Loss: 2.4547 | Val Loss: 1.0447 | Acc:  77.06% | Current LR(s): [0.000047, 0.000094, 0.000283, 0.000755, 0.001888]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  44%|█████████████████▏                     | 44/100 [9:34:23<14:21:06, 922.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [044/100] | Val Loss: 1.04471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  45%|█████████████████▌                     | 45/100 [9:49:37<14:03:21, 920.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [045/100] | Train Loss: 2.4364 | Val Loss: 1.0693 | Acc:  76.44% | Current LR(s): [0.000049, 0.000097, 0.000291, 0.000777, 0.001942]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  46%|█████████████████▍                    | 46/100 [10:05:03<13:49:46, 921.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [046/100] | Train Loss: 2.4108 | Val Loss: 1.0825 | Acc:  77.22% | Current LR(s): [0.000049, 0.000099, 0.000297, 0.000792, 0.001979]\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  47%|█████████████████▊                    | 47/100 [10:20:44<13:39:32, 927.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [047/100] | Train Loss: 2.3959 | Val Loss: 1.0665 | Acc:  77.58% | Current LR(s): [0.000050, 0.000100, 0.000300, 0.000799, 0.001998]\n",
      "No improvement for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  47%|█████████████████▊                    | 47/100 [10:36:23<13:39:32, 927.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [048/100] | Train Loss: 2.4040 | Val Loss: 1.0288 | Acc:  78.06% | Current LR(s): [0.000050, 0.000100, 0.000300, 0.000800, 0.002000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  48%|██████████████████▏                   | 48/100 [10:37:01<13:36:44, 942.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [048/100] | Val Loss: 1.02882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  49%|██████████████████▌                   | 49/100 [10:52:44<13:21:19, 942.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [049/100] | Train Loss: 2.4065 | Val Loss: 1.0530 | Acc:  77.08% | Current LR(s): [0.000050, 0.000100, 0.000299, 0.000798, 0.001996]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  49%|██████████████████▌                   | 49/100 [11:08:37<13:21:19, 942.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [050/100] | Train Loss: 2.3980 | Val Loss: 1.0060 | Acc:  78.22% | Current LR(s): [0.000050, 0.000099, 0.000298, 0.000796, 0.001989]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|███████████████████                   | 50/100 [11:09:13<13:17:00, 956.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [050/100] | Val Loss: 1.00600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|███████████████████                   | 50/100 [11:24:54<13:17:00, 956.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [051/100] | Train Loss: 2.3886 | Val Loss: 0.9876 | Acc:  77.96% | Current LR(s): [0.000049, 0.000099, 0.000297, 0.000791, 0.001978]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  51%|███████████████████▍                  | 51/100 [11:25:33<13:06:56, 963.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [051/100] | Val Loss: 0.98757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  52%|███████████████████▏                 | 52/100 [11:43:58<13:24:42, 1005.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [052/100] | Train Loss: 2.3898 | Val Loss: 0.9966 | Acc:  78.74% | Current LR(s): [0.000049, 0.000098, 0.000295, 0.000786, 0.001964]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  53%|████████████████████▏                 | 53/100 [11:59:53<12:56:00, 990.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [053/100] | Train Loss: 2.3844 | Val Loss: 1.0227 | Acc:  78.90% | Current LR(s): [0.000049, 0.000097, 0.000292, 0.000779, 0.001946]\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  54%|████████████████████▌                 | 54/100 [12:15:41<12:29:38, 977.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [054/100] | Train Loss: 2.3495 | Val Loss: 0.9940 | Acc:  78.14% | Current LR(s): [0.000048, 0.000096, 0.000289, 0.000770, 0.001925]\n",
      "No improvement for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  55%|████████████████████▉                 | 55/100 [12:31:25<12:05:51, 967.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [055/100] | Train Loss: 2.3653 | Val Loss: 1.0683 | Acc:  77.66% | Current LR(s): [0.000048, 0.000095, 0.000285, 0.000760, 0.001901]\n",
      "No improvement for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  55%|████████████████████▉                 | 55/100 [12:47:11<12:05:51, 967.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [056/100] | Train Loss: 2.3571 | Val Loss: 0.9729 | Acc:  78.62% | Current LR(s): [0.000047, 0.000094, 0.000281, 0.000749, 0.001873]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  56%|█████████████████████▎                | 56/100 [12:47:59<11:55:31, 975.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at epoch [056/100] | Val Loss: 0.97290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  57%|█████████████████████▋                | 57/100 [13:03:44<11:32:40, 966.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [057/100] | Train Loss: 2.3525 | Val Loss: 1.0304 | Acc:  78.94% | Current LR(s): [0.000046, 0.000092, 0.000276, 0.000737, 0.001843]\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  58%|██████████████████████                | 58/100 [13:19:25<11:11:07, 958.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [058/100] | Train Loss: 2.3516 | Val Loss: 1.0017 | Acc:  79.68% | Current LR(s): [0.000045, 0.000090, 0.000271, 0.000724, 0.001809]\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  59%|██████████████████████▍               | 59/100 [13:35:03<10:50:59, 952.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [059/100] | Train Loss: 2.3263 | Val Loss: 1.0246 | Acc:  78.46% | Current LR(s): [0.000044, 0.000089, 0.000266, 0.000709, 0.001772]\n",
      "No improvement for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████████████████████▊               | 60/100 [13:50:45<10:32:54, 949.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [060/100] | Train Loss: 2.3179 | Val Loss: 1.0810 | Acc:  78.58% | Current LR(s): [0.000043, 0.000087, 0.000260, 0.000693, 0.001733]\n",
      "No improvement for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  61%|███████████████████████▏              | 61/100 [14:06:50<10:20:07, 954.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [061/100] | Train Loss: 2.3090 | Val Loss: 1.0115 | Acc:  79.18% | Current LR(s): [0.000042, 0.000085, 0.000254, 0.000676, 0.001691]\n",
      "No improvement for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  62%|███████████████████████▌              | 62/100 [14:23:14<10:09:49, 962.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [062/100] | Train Loss: 2.3075 | Val Loss: 1.0850 | Acc:  78.96% | Current LR(s): [0.000041, 0.000082, 0.000247, 0.000659, 0.001647]\n",
      "No improvement for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  63%|████████████████████████▌              | 63/100 [14:39:34<9:57:01, 968.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [063/100] | Train Loss: 2.2986 | Val Loss: 0.9976 | Acc:  78.74% | Current LR(s): [0.000040, 0.000080, 0.000240, 0.000640, 0.001600]\n",
      "No improvement for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  64%|████████████████████████▉              | 64/100 [14:56:05<9:44:55, 974.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [064/100] | Train Loss: 2.2875 | Val Loss: 1.0269 | Acc:  79.38% | Current LR(s): [0.000039, 0.000078, 0.000233, 0.000620, 0.001551]\n",
      "No improvement for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  65%|█████████████████████████▎             | 65/100 [15:12:38<9:31:55, 980.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [065/100] | Train Loss: 2.3004 | Val Loss: 1.0223 | Acc:  79.34% | Current LR(s): [0.000037, 0.000075, 0.000225, 0.000600, 0.001500]\n",
      "No improvement for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  65%|█████████████████████████▎             | 65/100 [15:33:08<8:22:27, 861.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [066/100] | Train Loss: 2.2987 | Val Loss: 1.0014 | Acc:  79.66% | Current LR(s): [0.000036, 0.000072, 0.000217, 0.000579, 0.001447]\n",
      "No improvement for 10 epochs.\n",
      "Early stopping triggered in epoch [066/100] | Best Val Loss: [0.972897]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(100), desc=\"Training Epochs\", ncols=100):\n",
    "\n",
    "    if epoch == 0 and current_stage == 1:\n",
    "\n",
    "        tqdm.write(\"Stage 1: Training only FC layer\")\n",
    "        unfreeze_layers(resnet50, current_stage)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=10, pct_start=0.3, anneal_strategy=\"cos\")\n",
    "        current_stage = 2\n",
    "    \n",
    "    if epoch == 10 and current_stage == 2:\n",
    "        \n",
    "        tqdm.write(\"Stage 2: Unfreezing layer4 + layer3\")\n",
    "        unfreeze_layers(resnet50, current_stage)\n",
    "\n",
    "        optimizer = optim.SGD([\n",
    "            {'params': resnet50.layer3.parameters(), 'lr': 0.0005},\n",
    "            {'params': resnet50.layer4.parameters(), 'lr': 0.001},\n",
    "            {'params': resnet50.fc.parameters(), 'lr': 0.005}\n",
    "        ], momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=[0.0005, 0.001, 0.005], steps_per_epoch=len(train_loader), epochs=15, pct_start=0.3, anneal_strategy=\"cos\")\n",
    "        patience_counter = 0\n",
    "        current_stage = 3\n",
    "        \n",
    "    if epoch == 25 and current_stage == 3:\n",
    "\n",
    "        tqdm.write(\"Stage 3: Unfreezing all layers\")\n",
    "        unfreeze_layers(resnet50, current_stage)\n",
    "\n",
    "        optimizer = optim.SGD([\n",
    "            {'params': resnet50.layer1.parameters(), 'lr': 0.00005},\n",
    "            {'params': resnet50.layer2.parameters(), 'lr': 0.0001},\n",
    "            {'params': resnet50.layer3.parameters(), 'lr': 0.0003},\n",
    "            {'params': resnet50.layer4.parameters(), 'lr': 0.0008},\n",
    "            {'params': resnet50.fc.parameters(), 'lr': 0.002}\n",
    "        ], momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=[0.00005, 0.0001, 0.0003, 0.0008, 0.002], steps_per_epoch=len(train_loader), epochs=75, pct_start=0.3, anneal_strategy=\"cos\")\n",
    "        patience_counter = 0\n",
    "        \n",
    "    train_loss = train_one_epoch(resnet50, train_loader, optimizer, loss_fn_train, device, scheduler, mix)\n",
    "    val_loss, val_acc = evaluate(resnet50, val_loader, loss_fn_eval, device)\n",
    "\n",
    "    tqdm.write(f\"Epoch: [{epoch + 1:03d}/100] | \"\n",
    "    f\"Train Loss: {train_loss:.4f} | \"\n",
    "    f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:6.2f}%\", end=\" \")\n",
    "\n",
    "    lrs = [f\"{pg['lr']:.6f}\" for pg in optimizer.param_groups]\n",
    "    tqdm.write(f\"| Current LR(s): [{', '.join(lrs)}]\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": resnet50.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"total_params\": sum(p.numel() for p in resnet50.parameters())\n",
    "            },\n",
    "            f\"model_checkpoint.pth\"\n",
    "        )\n",
    "\n",
    "        tqdm.write(f\"Best model saved at epoch [{epoch + 1:03d}/100] | Val Loss: {val_loss:.5f}\")\n",
    "        \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        tqdm.write(f\"No improvement for {patience_counter} epochs.\")\n",
    "        if patience_counter >= max_patience:\n",
    "            tqdm.write(f\"Early stopping triggered in epoch [{epoch + 1:03d}/100] | Best Val Loss: [{best_val_loss:.6f}]\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "749b7b26-924d-4f60-af73-7f4e67699f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model...\n",
      "Test loss: 0.762229 | Test acc: 84.35%\n"
     ]
    }
   ],
   "source": [
    "# Final Evaluation\n",
    "print(\"Loading best model...\")\n",
    "\n",
    "final_model = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "num_features = final_model.fc.in_features\n",
    "final_model.fc = nn.Linear(num_features, 100)\n",
    "\n",
    "checkpoint = torch.load(\"model_checkpoint.pth\")\n",
    "\n",
    "final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "final_model.to(device)\n",
    "\n",
    "test_loss, test_acc = evaluate(final_model, test_loader, loss_fn_eval, device)\n",
    "print(f\"Test loss: {test_loss:.6f} | Test acc: {test_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (dl-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
